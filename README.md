# Perceptron
Implement a simple 2-features Perceptron with graphic plotting at each iteration.

## What is Perceptron?
æ„ŸçŸ¥å™¨Perceptron (ä¹Ÿç¨±ç‚ºPerceptron Learning Algorithmç°¡ç¨±PLA)
- ç·šæ€§å¯åˆ†
 ï¼ˆ2Dï¼šåœ¨å¹³é¢ä¸Šæ‰¾ä¸€æ¢ç·šå»å®Œå…¨åˆ‡å‡ºé€™å…©ç¾¤ï¼›3Dï¼šçš„è©±å°±æ˜¯å¯ä»¥åœ¨ç©ºé–“ä¸­æ‰¾ä¸€å€‹å¹³é¢å»åˆ‡å‡ºå…©ç¾¤ï¼‰
- ç•¶w1*x1 + w2*x2 + w3*x3 +â€¦. wn*xn >æŸä¸€å€‹å®šå€¼(aka. threshold, -bias)ï¼Œå°±æœƒå‡ºç™¼ç¥ç¶“å…ƒç™¼é€ä¿¡è™Ÿå‡ºå»
- Activation FunctionæŒ‘é¸åƒsignä¸€æ¨£å°å‡ºé›¢æ•£åˆ†é¡çµæœçš„function

### Perceptron Algorithm
![perceptron algorithm](https://cdn-images-1.medium.com/max/1600/1*MofmXIxbv5AOIXHQp_hSOw.png)

Figure 1. Perceptron Algorithm (by Yeh James)

#### How to Learn?
å¹³é¢çš„æ³•å‘é‡ç‚ºW, æ³•å‘é‡æŒ‡å‘çš„è¼¸å…¥ç©ºé–“ï¼Œå…¶è¼¸å‡ºå€¼ç‚º+1ï¼Œè€Œèˆ‡æ³•å‘é‡åå‘çš„è¼¸å…¥ç©ºé–“ï¼Œå…¶è¼¸å‡ºå€¼ç‚º-1ã€‚

æ¯æ¬¡è¿­ä»£:

1. Inputç‚ºä¸€ç­†è³‡æ–™çš„featuresï¼ŒPerceptronå°‡featuresåˆ†åˆ¥è·ŸWeightsç›¸ä¹˜å†åŠ biasï¼Œé€éActivationäºŒå…ƒåˆ†é¡æƒ…æ³çš„è©±å°‡outputç¶“ç”±Sign()å°‡è³‡æ–™åˆ†æˆå…©å€‹çµæœ[-1, 1]

2. å°‡æ‰€æœ‰Outputsèˆ‡å…¶ç›¸å°ä¹‹targetsæ¯”è¼ƒï¼Œæ‰¾å‡ºå…¶ä¸­ä¸€ç­†error Dataå‡ºä¾†update weights
ç”¨x åˆ°åŸé»çš„å‘é‡ X ,ä¾†ä¿®æ­£ç›´ç·šçš„æ³•å‘é‡ W

è¦æ€éº¼ä¿®æ­£å‘¢ï¼Ÿè¦çœ‹ x çš„é¡åˆ¥ y ä¾†æ±ºå®š, èª¿æ•´ Wçš„æ–¹å‘

å…¬å¼å¦‚ä¸‹ï¼š
> W â†’ W + yâ‹…X

ç”¨é€™å€‹æ–¹æ³•å°±å¯ä»¥æ”¹è®Šç›´ç·šçš„æ–œç‡,æŠŠåˆ†é¡éŒ¯èª¤çš„é» x ,æ­¸åˆ°æ­£ç¢ºçš„ä¸€é¡ã€‚

3. é‡æ–°è¿­ä»£ç›´è‡³æ²’æœ‰errorç‚ºæ­¢


#### Pros & Cons
Perceptionå„ªé»ï¼š

- æœ€ç°¡å–®çš„ç·šæ€§åˆ†é¡æ¼”ç®—æ³•ï¼ŒPerceptionæ¼”ç®—æ³•çš„åŸç†å¯æ¨å»£è‡³å…¶ä»–è¤‡é›œçš„æ¼”ç®—æ³•ã€‚

Perceptionç¼ºé»ï¼š

- ä¸€å®šè¦ç·šæ€§å¯åˆ†Perceptionæ¼”ç®—æ³•æ‰æœƒåœä¸‹ä¾†ï¼ˆå¯¦å‹™ä¸Šæˆ‘å€‘æ²’è¾¦æ³•äº‹å…ˆçŸ¥é“è³‡æ–™æ˜¯å¦ç·šæ€§å¯åˆ†ï¼‰
- Perceptionæ¼”ç®—æ³•çš„éŒ¯èª¤ç‡ä¸æœƒé€æ­¥æ”¶æ–‚
- Perceptionæ¼”ç®—æ³•åªçŸ¥é“çµæœæ˜¯Aé¡é‚„Bé¡ï¼Œä½†æ²’è¾¦æ³•çŸ¥é“æ˜¯A, Bé¡çš„æ©Ÿç‡æ˜¯å¤šå°‘ï¼ˆLogistic regressionå¯è§£æ±ºæ­¤å•é¡Œï¼‰

#### Any Questions?
Q: What kind of problems can it fix?

A: Binary Classification (äºŒå…ƒåˆ†é¡), a type of linear classifier


Q: Can it solve multiclass problems?

A: æœ‰é»éº»ç…©ï¼Œåƒè€ƒåˆ¥äººçš„ä¾‹å­ï¼š

Suppose we have data (ğ‘¥1,ğ‘¦1),â€¦,(ğ‘¥ğ‘˜,ğ‘¦ğ‘˜) where ğ‘¥ğ‘–âˆˆâ„ğ‘› are input vectors and ğ‘¦ğ‘–âˆˆ{red, blue, green} are the classifications.

We know how to build a classifier for binary outcomes, so we do this three times: group the outcomes together, {red, blue or green},{blue, red or green} and {green, blue or red}.



## Version
1.0

## Requirements
```
Python==3.5.2
numpy==1.15.4
pandas==0.18.1
```
## Coding Description
#### Activation Function: Sign
#### Error: count the numbers of error data


## Demo 

a binary classifier with Iris Data ï¼ˆç¶“filterå¾Œæœ‰100ç­†è³‡æ–™ï¼‰
ä»¥Iris è³‡æ–™é›†ä¾†åšè³‡æ–™ç·šæ€§å¯åˆ†çš„è¦–è¦ºåŒ–, é¸å‡ºå…¶ä¸­2ç¨®ç‰¹å¾µ(inputs) and2ç¨®èŠ±çš„ç¨®é¡(output)

#### Input datasets
```
# as a dataframe
from sklearn import datasets

iris_data = iris_data_preprocess()
iris_data.head()
```
```
   sepal length (cm)  petal length (cm)  target
0                5.1                1.4      -1
1                4.9                1.4      -1
2                4.7                1.3      -1
```

#### Build the Perceptron
```
myPerceptron = Perceptron(n_inputs=len(iris_data.columns)-1, save_fig=False)
```

#### Train
```
 myPerceptron.train(iris_data)
```

#### plot the final result
```
plot_data_and_line(iris_data, myPerceptron.weights, save_fig=False)
```



## References
Concepts:

- [ç¬¬3.3è¬›ï¼šç·šæ€§åˆ†é¡-é‚è¼¯æ–¯å›æ­¸(Logistic Regression) ä»‹ç´¹ by Yeh James](https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC3-3%E8%AC%9B-%E7%B7%9A%E6%80%A7%E5%88%86%E9%A1%9E-%E9%82%8F%E8%BC%AF%E6%96%AF%E5%9B%9E%E6%AD%B8-logistic-regression-%E4%BB%8B%E7%B4%B9-a1a5f47017e5)
- [æ©Ÿå™¨å­¸ç¿’--Perceptron Algorithm
 by Mark Chang](http://cpmarkchang.logdown.com/posts/189108-machine-learning-perceptron-algorithm)


Coding:

- [è¶…ç°¡å–®ç‰ˆperceptron learning algorithmå¯¦ä½œåŠç¯„ä¾‹](http://terrence.logdown.com/posts/290508-python-simple-perceptron-learning-algorithm-implementations)

